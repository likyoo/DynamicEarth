![demo](assets/DynamicEarth_logo.png)

<div align="center">

<h1>DynamicEarth: How Far are We from Open-Vocabulary Change Detection?</h1>

<div>
    <a href='https://likyoo.github.io/' target='_blank'>Kaiyu Li</a><sup>1</sup>&emsp;
    <a href='https://gr.xjtu.edu.cn/en/web/caoxiangyong' target='_blank'>Xiangyong Cao</a><sup>âœ‰1</sup>&emsp;
    <a href='https://github.com/BLING-1994' target='_blank'>Yupeng Deng</a><sup>2</sup>&emsp;
    <a href='https://github.com/fitzpchao' target='_blank'>Chao Pang</a><sup>3</sup>&emsp;
    <a href='https://github.com/xcarl1' target='_blank'>Zepeng Xin</a><sup>1</sup>&emsp;
    <a href='' target='_blank'>Hui Qiao</a><sup>4</sup>&emsp;
    <a href='https://gong-tl.github.io/' target='_blank'>Tieliang Gong</a><sup>1</sup>&emsp;
    <a href='https://gr.xjtu.edu.cn/en/web/dymeng' target='_blank'>Deyu Meng</a><sup>1</sup>&emsp;
    <a href='https://gr.xjtu.edu.cn/en/web/zhiwang' target='_blank'>Zhi Wang</a><sup>1</sup>&emsp;
</div>
<div>
    <sup>1</sup>Xi'an Jiaotong University&emsp;
    <sup>2</sup>Chinese Academy of Sciences&emsp;
    <sup>3</sup>Wuhan University&emsp;
    <sup>4</sup>China Telecom&emsp;
</div>

<div>
    <h4 align="center">
        â€¢ <a href="https://likyoo.github.io/DynamicEarth/" target='_blank'>[Project]</a> â€¢ <a href="https://arxiv.org/abs/2501.12931" target='_blank'>[arXiv]</a> â€¢ <a href="" target='_blank'>[Colab]</a> â€¢
    </h4>
</div>

<img src="https://github.com/user-attachments/assets/0530a114-e320-46a4-be0d-201c6dc22743" width="90%"/>
Different change detection tasks: (a) Binary change detection aims at discovering all (interested) changes and generating a binary mask; (b) Semantic change detection further identifies the category of changes. However, both can only be trained and evaluated on data with predefined categories; (c) Our proposed OVCD can detect changes in any category according to the user's requirements.

</div>

----

**ã€åœ°è¡¨æœ€å¼ºAIä¾¦æ¢ä¸Šçº¿ï¼DynamicEarthï¼šè®©é¥æ„Ÿå›¾åƒå›¾åƒå˜åŒ–æ£€æµ‹ç§’å˜"å¤§å®¶æ¥æ‰¾èŒ¬"Pro Maxç‰ˆğŸŒğŸ”ã€‘**

å„ä½çœ‹å®˜ï¼è¿˜åœ¨ä¸ºä¼ ç»Ÿå˜åŒ–æ£€æµ‹æ¨¡å‹"æ­»è®°ç¡¬èƒŒ"æœ‰é™ç±»åˆ«è€Œå¤´ç§ƒå—ï¼Ÿæˆ‘ä»¬æ‰“é€ çš„å¼€æ”¾è¯æ±‡å˜åŒ–æ£€æµ‹ï¼ˆOVCDï¼‰é»‘ç§‘æŠ€ï¼Œè®©AIç§’å˜"ç«çœ¼é‡‘ç›"â€”â€”æ— éœ€996å¼è®­ç»ƒï¼Œç›´æ¥è°ƒç”¨ç°æˆåŸºç¡€æ¨¡å‹ï¼Œå°±èƒ½åœ¨å«æ˜Ÿå›¾ä¸Šç©è½¬"å¤§å®¶æ¥æ‰¾èŒ¬"ï¼

ğŸ‘‰ ä¸¤å¤§ç»æ‹›æ¨ªæ‰«æ±Ÿæ¹–ï¼š

1ï¸âƒ£ **â€‹M-C-Iæ¡†æ¶**ï¼š"å…ˆåœˆåœ°å†ç ´æ¡ˆ"æ¨¡å¼â€”â€”SAMæ¨¡å‹åƒæ’’ç½‘æ•é±¼èˆ¬åœˆå‡ºå¯ç–‘åŒºåŸŸï¼ŒDINOåŒ–èº«ç¦å°”æ‘©æ–¯æ¯”å¯¹ç‰¹å¾ï¼Œæœ€åCLIPå¤§ä½¬å¼€å£å®šç½ªåï¼š"æŠ¥å‘Šï¼è¿™é‡Œä»å·¥åœ°å˜æ³³æ± äº†ï¼ğŸ—â†’ğŸŠ"

2ï¸âƒ£ **â€‹I-M-Cæ¡†æ¶**ï¼š"æŒ‡å“ªæ‰“å“ª"æ¨¡å¼â€”â€”Grounding DINOå…ˆé”å®šç›®æ ‡ï¼š"ç»™æˆ‘ç›¯æ­»è¿™ç‰‡åˆ«å¢…åŒºï¼" SAMç«‹åˆ»ç”»å‡ºç²¾ç¡®è½®å»“ï¼ŒDINOç¿»å‡ºå†å²æ¡£æ¡ˆå¯¹æ¯”ï¼š"è€æ¿ï¼Œ3å·æ¥¼å·å·åŠ ç›–äº†ä¸¤å±‚ï¼"

ğŸ’¡ äº”å¤§æ€æ‰‹é”ï¼š

âœ”ï¸ å¼€æ”¾è¯æ±‡ä»»ä½ æ’©ï¼šä»"æŸ¥è¿ç« å»ºç­‘"åˆ°"æ‰¾æ–°å¼€ä½“è‚²åœº"ï¼Œè¾“å…¥æ–‡å­—æŒ‡ä»¤å°±èƒ½ç²¾å‡†å®šä½

âœ”ï¸ é›¶è®­ç»ƒå¼€ç®±å³ç”¨ï¼šå‘Šåˆ«ç‚¼ä¸¹å¼è°ƒå‚ï¼Œç°æœ‰æ¨¡å‹ç›´æ¥"æ‹¼ç§¯æœ¨"

âœ”ï¸ æŠ—å¹²æ‰°èƒ½åŠ›MAXï¼šå…‰ç…§å˜åŒ–ï¼Ÿå­£èŠ‚æ›´æ›¿ï¼Ÿæˆ‘ä»¬çš„AIä¾¦æ¢ç»ä¸"ç–‘ç¥ç–‘é¬¼"

âœ”ï¸ è·¨æ•°æ®é›†ä¹±æ€ï¼šåœ¨LEVIR-CDç­‰äº”å¤§æ“‚å°èµ›åŠæ‰“ä¼ ç»Ÿæ–¹æ³•ï¼ŒF1åˆ†æ•°é£™å‡30%+

âœ”ï¸ ä»£ç å…¨å®¶æ¡¶å¥‰ä¸Šï¼šDynamicEarthå¼€æºåº“å·²å°±ä½ï¼Œå°±å·®ä½ æ¥Starâ­ï¸


----

**"DynamicEarth: Where Satellite Sleuthing Meets Open-World Wizardry!"** ğŸŒğŸ•µï¸â™‚ï¸

Calling all geo-detectives! Tired of change detection models stuck in "I-Spy-20-Objects" mode? Meet our â€‹**Open-Vocabulary Change Detection (OVCD)** â€“ the Sherlock Holmes of satellite imagery that cracks any visual case you throw at it, â€‹zero training required!

ğŸš€ **â€‹Two Frameworks to Rule Them All:**

1ï¸âƒ£ **â€‹M-C-I Protocol**: "Mask first, ask later!"

- **â€‹SAM** sprays "detective spray" to highlight suspicious zones ğŸ•¸ï¸
- **DINO** plays spot-the-difference with NASA-level precision ğŸ”
- **CLIP** drops the mic: "This construction site just morphed into a waterpark!" ğŸ—ï¸ğŸ’¦

2ï¸âƒ£ **â€‹I-M-C** Maneuver: "Name it, claim it!"

- Point at a target: "Track every swimming pool in Dubai!" ğŸŠâ™‚ï¸

- **â€‹Grounding DINO** snaps to attention ğŸ‘®â™‚ï¸

- **â€‹SAM** outlines targets like a crime scene investigator ğŸš§

- **â€‹DINO** cross-examines timelines: "Pool #5 shrank 2 meters â€“ violation alert!" ğŸš¨

ğŸ’¥ â€‹Why This Rocks:

âœ”ï¸ **â€‹Vocabulary? We Donâ€™t Know Her:** Detect "illegal rooftop extensions" or "mysterious crop circles" with equal flair ğŸŒ¾ğŸ‘½

âœ”ï¸ **â€‹No-Training Wheels:** Skip endless training marathons â€“ our modelâ€™s already bench-pressing foundation models ğŸ’ª

âœ”ï¸ **â€‹Pseudo-Change? GTFO:** Seasons change? Shadows shift? Our AIâ€™s got trust issues (in a good way) â˜€ï¸â„ï¸

âœ”ï¸ **â€‹Dataset Domination:** Crushed LEVIR-CD/WHU-CD benchmarks like Godzilla in Tokyo ğŸ™ï¸ğŸ’¥

âœ”ï¸ **â€‹Open-Source Swagger:** DynamicEarth codebase â€“ now 100% less "secret sauce"! ğŸ‘©ğŸ’»ğŸ”“


----

<div align="center">

<img src="https://github.com/user-attachments/assets/94b58131-4593-415b-9e44-0ee790f884ef" width="90%"/>

The two OVCD frameworks proposed in this paper. (a) M-C-I: discover all class-agnostic masks, determine if the mask region has changed, and identify the change class. (b) I-M-C: identify all targets of interest, convert to mask format, and compare if the target has changed.

</div>

## Abstract

Monitoring Earth's evolving land covers requires methods capable of detecting changes across a wide range of categories and contexts. Existing change detection methods are hindered by their dependency on predefined classes, reducing their effectiveness in open-world applications. To address this issue, we introduce open-vocabulary change detection (OVCD), a novel task that bridges vision and language to detect changes across any category. Considering the lack of high-quality data and annotation, we propose two training-free frameworks, M-C-I and I-M-C, which leverage and integrate off-the-shelf foundation models for the OVCD task. The insight behind the M-C-I framework is to discover all potential changes and then classify these changes, while the insight of I-M-C framework is to identify all targets of interest and then determine whether their states have changed. Based on these two frameworks, we instantiate to obtain several methods, e.g., SAM-DINOv2-SegEarth-OV, Grounding-DINO-SAM2-DINO, etc. Extensive evaluations on 5 benchmark datasets demonstrate the superior generalization and robustness of our OVCD methods over existing supervised and unsupervised methods. To support continued exploration, we release DynamicEarth, a dedicated codebase designed to advance research and application of OVCD.

## Dependencies and Installation

Our code depends on [PyTorch](https://pytorch.org/), [Detectron](https://github.com/facebookresearch/detectron2), [OpenMMLab](https://github.com/open-mmlab), [SAM](https://github.com/facebookresearch/segment-anything) ... ... 

Please refer to [Install Guide](install.md) for more detailed instruction.

## Demo

SAM_DINO_SegEarth-OV
```
python sam_dino_segearth-ov_demo.py --input_image_1 demo_images/A/test_1024.png --input_image_2 demo_images/B/test_1024.png
```

SAM_DINOv2_SegEarth-OV
```
python sam_dinov2_segearth-ov_demo.py --input_image_1 demo_images/A/test_1024.png --input_image_2 demo_images/B/test_1024.png
```

Grounding DINO 1.5-SAM2-DINO
```
# Get your API token from https://cloud.deepdataspace.com
python gd1.5_sam2_demo.py --gd_api_token [YOUR_TOKEN] --input_image_1 demo_images/A/test_256.png --input_image_2 demo_images/B/test_256.png 
```

APE-DINO
```
python ape_dino_demo.py --input_image_1 demo_images/A/test_256.png --input_image_2 demo_images/B/test_256.png 
```

APE-DINOv2
```
python ape_dinov2_demo.py --input_image_1 demo_images/A/test_256.png --input_image_2 demo_images/B/test_256.png 
```

MMGrounding DINO-SAM2-DINO
```
python mmgd_sam2_dino_demo.py --input_image_1 demo_images/A/test_256.png --input_image_2 demo_images/B/test_256.png 
```

## Evaluation

We provide comprehensive evaluation scripts for the [LEVIR-CD](https://justchenhao.github.io/LEVIR/), [WHU-CD](http://gpcv.whu.edu.cn/data/building_dataset.html), [S2Looking](https://github.com/S2Looking/Dataset), [BANDON](https://github.com/fitzpchao/BANDON), [SECOND](https://captain-whu.github.io/SCD/) datasets and you can find them in [eval](eval).

## Results

<div align="center">

<div>
<img src="https://github.com/user-attachments/assets/fa5ccb8e-cb59-447f-87b8-2caf30e8e5ee" width="70%"/>
</div>

<div>
<img src="https://github.com/user-attachments/assets/491156f3-ecd8-47b7-bc03-c5aa37c33e96" width="70%"/>
</div>

<div>
<img src="https://github.com/user-attachments/assets/2e11f37a-4a89-4e3c-997c-af3cb42ae290" width="70%"/>
</div>
</div>

## Visualization

<div>
<img src="https://github.com/user-attachments/assets/5c368d37-862d-4f6e-9702-c0bce3d48fba" width="100%"/>
</div>



## Citation

```
@article{li2025dynamicearth,
  title={DynamicEarth: How Far are We from Open-Vocabulary Change Detection?},
  author={Li, Kaiyu and Cao, Xiangyong and Deng, Yupeng and Pang, Chao and Xin, Zepeng and Meng, Deyu and Wang, Zhi},
  journal={arXiv preprint arXiv:2501.12931},
  year={2025}
}
```

## Acknowledgement

We sincerely appreciate the following:

- [AngChange](https://github.com/Z-Zheng/pytorch-change-models/tree/main/torchange/models/segment_any_change)
- [Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything)
- [UCD-SCM](https://github.com/StephenApX/UCD-SCM)

